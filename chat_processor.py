import os
import pandas as pd
import re
from typing import Dict, Any, List
import logging
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
import math
import json
import asyncio
import re
import time
from astrapy import DataAPIClient
from openai import OpenAI
from memory import ConversationMemory
from langchain_anthropic import ChatAnthropic

# Config imports - GuidanceTemplates kaldƒ±rƒ±ldƒ±
from config import (
    LLMConfigs, LLMProvider, VectorConfig, CSVConfig,
    PromptTemplates, CSV_KEYWORDS,
    DatabaseSettings, MessageSettings, AppSettings
)

logger = logging.getLogger(__name__)

class LLMFactory:
    @staticmethod
    def create_llm(config):
        """Geli≈ümi≈ü hata y√∂netimi ile LLM olu≈ütur"""
        try:
            params = config.to_langchain_params()
            if AppSettings.DEBUG_MODE:
                logger.debug(f"LLM creating: {config.provider.value} - {config.model}")
            
            if config.provider == LLMProvider.OPENAI:
                from langchain_openai import ChatOpenAI
                return ChatOpenAI(**params)
            elif config.provider == LLMProvider.GOOGLE:
                from langchain_google_genai import ChatGoogleGenerativeAI
                return ChatGoogleGenerativeAI(**params)
            elif config.provider == LLMProvider.ANTHROPIC:
                from langchain_anthropic import ChatAnthropic
                return ChatAnthropic(**params)
            else:
                raise ValueError(f"Unsupported provider: {config.provider}")
                
        except Exception as e:
            logger.error(f"LLM creation error ({config.provider.value}): {e}")
            raise

class TercihAsistaniProcessor:
    """
    G√ºncellenmi≈ü processor - Tek Tutarlƒ± Ton Yakla≈üƒ±mƒ±
    """
    
    def __init__(self):
        # Smart Evaluator-Corrector
        self.llm_smart_evaluator_corrector = None
        
        # KALAN LLM'LER
        self.llm_csv_agent = None
        self.llm_final = None
        
        # Native Astrapy components
        self.openai_client = None
        self.astra_database = None
        self.astra_collection = None
        
        self.csv_data = None
        self.memory = ConversationMemory() 
        
        # PROMPT'LAR - guidance parametreleri kaldƒ±rƒ±ldƒ±
        self.smart_evaluator_corrector_prompt = ChatPromptTemplate.from_template(
            PromptTemplates.SMART_EVALUATOR_CORRECTOR
        )
        
        self.csv_agent_prompt = ChatPromptTemplate.from_template(PromptTemplates.CSV_AGENT)
        self.final_prompt = ChatPromptTemplate.from_template(PromptTemplates.FINAL_RESPONSE)

    def get_embedding(self, text: str) -> List[float]:
        """OpenAI embedding olu≈ütur"""
        try:
            response = self.openai_client.embeddings.create(
                input=text,
                model="text-embedding-3-small"
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Embedding creation error: {e}")
            raise

    def _get_recent_history(self, session_id: str, limit: int = 4) -> str:
        """Son N mesajƒ± al - Smart Evaluator i√ßin"""
        try:
            if not self.memory:
                return ""
            
            # Memory'den son mesajlarƒ± al
            full_history = self.memory.get_history(session_id, limit=limit)
            
            if not full_history:
                return ""
            
            # Son 2-3 mesaj √ßiftini al (user-assistant pairs)
            lines = full_history.strip().split('\n')
            recent_lines = lines[-4:] if len(lines) >= 4 else lines  # Son 4 satƒ±r (2 mesaj √ßifti)
            
            recent_history = '\n'.join(recent_lines)
            
            if AppSettings.LOG_MEMORY_OPERATIONS:
                logger.debug(f"Recent history retrieved: {len(recent_history)} chars")
            
            return recent_history
            
        except Exception as e:
            logger.error(f"Recent history error: {e}")
            return ""

    async def initialize(self):
        """G√ºncellenmi≈ü ba≈ülatma"""
        try:
            logger.info("TercihAsistaniProcessor initializing...")
            
            # API Key kontrol√º
            self._check_api_keys()
            
            # OpenAI client'ƒ± ba≈ülat
            self._initialize_openai_client()
            
            # LLM'leri sƒ±ralƒ± ba≈ülat
            await self._initialize_llms_new()
            
            # AstraDB baƒülantƒ±sƒ±nƒ± native API ile ba≈ülat
            await self._initialize_astradb_native()
            
            # CSV verilerini y√ºkle
            await self._initialize_csv()
                
            logger.info("TercihAsistaniProcessor initialized successfully")
            
        except Exception as e:
            logger.error(f"Initialization error: {e}")
            raise

    def _check_api_keys(self):
        """API anahtarlarƒ±nƒ± kontrol et"""
        keys = {
            "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
            "ANTHROPIC_API_KEY": os.getenv("ANTHROPIC_API_KEY"),
            "GOOGLE_API_KEY": os.getenv("GOOGLE_API_KEY"),
            "ASTRA_DB_TOKEN": os.getenv("ASTRA_DB_TOKEN"),
            "ASTRA_DB_API_ENDPOINT": os.getenv("ASTRA_DB_API_ENDPOINT")
        }
        
        logger.info("API Key status check:")
        for key, value in keys.items():
            status = "Set" if value else "Missing"
            if AppSettings.DEBUG_MODE:
                logger.debug(f"   {key}: {status}")
            
        # Critical keys check
        if not keys["OPENAI_API_KEY"]:
            raise ValueError("OPENAI_API_KEY is required!")

    def _initialize_openai_client(self):
        """OpenAI client'ƒ± ba≈ülat"""
        try:
            self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            logger.info("OpenAI client initialized")
        except Exception as e:
            logger.error(f"OpenAI client error: {e}")
            raise

    async def _initialize_llms_new(self):
        """LLM ba≈ülatma"""
        llm_configs = {
            "smart_evaluator_corrector": LLMConfigs.SMART_EVALUATOR_CORRECTOR,
            "csv_agent": LLMConfigs.CSV_AGENT,
            "final": LLMConfigs.FINAL_RESPONSE
        }
        
        for name, config in llm_configs.items():
            try:
                llm = LLMFactory.create_llm(config)
                setattr(self, f"llm_{name}", llm)
                logger.info(f"{name} LLM initialized: {config.model}")
                
            except Exception as e:
                logger.error(f"{name} LLM error: {e}")
                
                # Critical LLM'ler i√ßin fallback
                if name in ["smart_evaluator_corrector", "csv_agent", "final"]:
                    logger.warning(f"{name} using OpenAI fallback...")
                    fallback_config = LLMConfigs.FINAL_RESPONSE  # OpenAI model
                    try:
                        llm = LLMFactory.create_llm(fallback_config)
                        setattr(self, f"llm_{name}", llm)
                        logger.info(f"{name} fallback successful")
                    except Exception as fb_error:
                        logger.error(f"{name} fallback failed: {fb_error}")
                        setattr(self, f"llm_{name}", None)

    async def _initialize_astradb_native(self):
        """AstraDB native API ile baƒülantƒ±"""
        try:
            logger.info("Initializing AstraDB native API connection...")
            
            # Astra client olu≈ütur
            astra_client = DataAPIClient(DatabaseSettings.ASTRA_DB_TOKEN)
            
            # Database baƒülantƒ±sƒ±
            self.astra_database = astra_client.get_database(
                DatabaseSettings.ASTRA_DB_API_ENDPOINT
            )
            
            # Collection al
            collection_name = DatabaseSettings.ASTRA_DB_COLLECTION
            self.astra_collection = self.astra_database.get_collection(collection_name)
            
            logger.info(f"AstraDB connected - Collection: {collection_name}")
            
            # Test sorgusu
            test_results = list(self.astra_collection.find({}, limit=1))
            logger.info(f"Connection test successful: {len(test_results)} documents found")
            
        except Exception as e:
            logger.error(f"AstraDB connection error: {e}")
            self.astra_database = None
            self.astra_collection = None

    async def _initialize_csv(self):
        """CSV verilerini g√ºvenli y√ºkle"""
        try:
            csv_path = DatabaseSettings.CSV_FILE_PATH
            
            if not csv_path or not os.path.exists(csv_path):
                logger.warning(f"CSV file not found: {csv_path}")
                self.csv_data = None
                return
            
            self.csv_data = pd.read_csv(csv_path)
            
            # Veri validasyonu
            if self.csv_data.empty:
                logger.warning("CSV file is empty")
                self.csv_data = None
                return
            
            # Gerekli kolonlarƒ±n varlƒ±ƒüƒ±nƒ± kontrol et
            required_cols = ['bolum_adi', 'gosterge_id']
            missing_cols = [col for col in required_cols if col not in self.csv_data.columns]
            
            if missing_cols:
                logger.error(f"Missing CSV columns: {missing_cols}")
                self.csv_data = None
                return
            
            logger.info(f"CSV data loaded: {len(self.csv_data)} rows, {len(self.csv_data.columns)} columns")
            
        except Exception as e:
            logger.error(f"CSV loading error: {e}")
            self.csv_data = None

    async def _smart_evaluate_and_correct(self, message: str, session_id: str) -> Dict[str, str]:
        """Smart Evaluator-Corrector fonksiyonu - Sadele≈ütirilmi≈ü"""
        try:
            smart_start = time.time()
            
            if not self.llm_smart_evaluator_corrector:
                if AppSettings.LOG_LLM_RESPONSES:
                    logger.debug("Smart Evaluator-Corrector LLM unavailable, fallback")
                return {
                    "status": "UYGUN",
                    "enhanced_question": message
                }
            
            # Son birka√ß mesajƒ± al
            recent_history = self._get_recent_history(session_id, limit=4)
            
            if AppSettings.LOG_LLM_RESPONSES:
                logger.debug(f"Smart Evaluator starting: message_len={len(message)}, history_len={len(recent_history)}")
            
            # Smart Evaluator-Corrector'a g√∂nder
            result = await self.llm_smart_evaluator_corrector.ainvoke(
                self.smart_evaluator_corrector_prompt.format(
                    question=message,
                    history=recent_history
                )
            )
            
            response = result.content.strip()
            smart_time = time.time() - smart_start
            
            if AppSettings.LOG_LLM_RESPONSES:
                logger.debug(f"Smart Evaluator response ({smart_time:.2f}s): {response[:100]}...")
            
            # Response'u parse et
            try:
                # STATUS ve ENHANCED_QUESTION'u extract et
                status_match = re.search(r'STATUS:\s*(\w+)', response)
                question_match = re.search(r'ENHANCED_QUESTION:\s*(.+)', response, re.DOTALL)
                
                if status_match and question_match:
                    status = status_match.group(1).strip()
                    enhanced_question = question_match.group(1).strip()
                    
                    if AppSettings.LOG_LLM_RESPONSES:
                        logger.debug(f"Parse successful: Status={status}, Enhanced_len={len(enhanced_question)}")
                    
                    return {
                        "status": status,
                        "enhanced_question": enhanced_question
                    }
                else:
                    if AppSettings.LOG_LLM_RESPONSES:
                        logger.debug("Parse failed - format error, using fallback")
                    
                    # Fallback parsing
                    if "META_BOT" in response.upper():
                        return {"status": "META_BOT", "enhanced_question": message}
                    elif "UYGUN" in response.upper():
                        return {"status": "UYGUN", "enhanced_question": message}
                    elif "SELAMLAMA" in response.upper():
                        return {"status": "SELAMLAMA", "enhanced_question": message}
                    else:
                        return {"status": "KAPSAM_DI≈ûI", "enhanced_question": message}
                        
            except Exception as parse_error:
                logger.error(f"Smart Evaluator parse error: {parse_error}")
                return {"status": "UYGUN", "enhanced_question": message}
            
        except Exception as e:
            smart_time = time.time() - smart_start
            logger.error(f"Smart Evaluator-Corrector error ({smart_time:.2f}s): {e}")
            return {"status": "UYGUN", "enhanced_question": message}

    async def process_message(self, message: str, session_id: str = "default") -> Dict[str, Any]:
        """YENƒ∞ akƒ±≈ü ile mesaj i≈üleme - Tek Tutarlƒ± Ton"""
        start_time = time.time()
        
        try:
            logger.info(f"Processing message: session={session_id}, length={len(message)}")
            
            # Adƒ±m 1: Smart Evaluator-Corrector
            smart_start = time.time()
            smart_result = await self._smart_evaluate_and_correct(message, session_id)
            smart_time = time.time() - smart_start
            
            status = smart_result["status"]
            enhanced_question = smart_result["enhanced_question"]
            
            # DETAYLI PERFORMANS LOGGING
            if os.getenv("DETAILED_TIMING", "false").lower() == "true":
                logger.info(f"‚è±Ô∏è Smart Evaluator: {smart_time:.2f}s, Status: {status}")
            
            # Adƒ±m 2: √ñzel durumlar (aynƒ± kaldƒ±)
            if status == "KAPSAM_DI≈ûI":
                total_time = time.time() - start_time
                logger.info(f"Out of scope request completed in {total_time:.2f}s")
                return {
                    "response": MessageSettings.ERROR_EXPERTISE_OUT,
                    "metadata": {"processing_time": round(total_time, 2)}
                }
            
            if status == "SELAMLAMA":
                total_time = time.time() - start_time
                logger.info(f"Greeting request completed in {total_time:.2f}s")
                return {
                    "response": "Merhaba! Ben bir √ºniversite tercih asistanƒ±yƒ±m. Size YKS tercihleri, b√∂l√ºm se√ßimi, kariyer planlamasƒ± konularƒ±nda yardƒ±mcƒ± olabilirim. Hangi konuda bilgi almak istiyorsunuz?",
                    "metadata": {"processing_time": round(total_time, 2)}
                }
            
            if status == "META_BOT":
                total_time = time.time() - start_time
                logger.info(f"Meta bot request completed in {total_time:.2f}s")
                
                meta_response = """Ben bir √ºniversite tercih asistanƒ±yƒ±m! üéì

**Nasƒ±l √ßalƒ±≈üƒ±yorum:**
‚Ä¢ Senin ilgi alanlarƒ±nƒ±, yeteneklerini ve hedeflerini anlamaya √ßalƒ±≈üƒ±rƒ±m
‚Ä¢ YKS tercihleri, b√∂l√ºm se√ßimi, kariyer planlamasƒ± konularƒ±nda yardƒ±mcƒ± olurum
‚Ä¢ Sana hazƒ±r cevap vermek yerine, doƒüru sorularƒ± sorarak d√º≈ü√ºnmeni kolayla≈ütƒ±rƒ±rƒ±m

**Ne konularda yardƒ±mcƒ± olabilirim:**
üëâ B√∂l√ºm se√ßimi ve kar≈üƒ±la≈ütƒ±rma
üëâ √úniversite/≈üehir tercihi
üëâ Kariyer planlama
üëâ ƒ∞stihdam ve maa≈ü verileri
üëâ Tercih stratejileri

Sen de bana hangi konuda yardƒ±ma ihtiya√ß duyduƒüunu s√∂yleyebilirsin! üòä"""
                
                # Memory'ye kaydet
                self.memory.add_message(session_id, "user", message)
                self.memory.add_message(session_id, "assistant", meta_response)
                
                return {
                    "response": meta_response,
                    "metadata": {
                        "processing_time": round(total_time, 2),
                        "mode": "meta_bot"
                    }
                }
            
            # Adƒ±m 3: NORMAL AKI≈û - T√úM UYGUN SORULAR AYNI YAKLA≈ûIMLA
            # REHBERLƒ∞K_GEREKTƒ∞REN durumu kaldƒ±rƒ±ldƒ± - hepsi aynƒ± akƒ±≈üa gidiyor
            
            parallel_start = time.time()
            
            # Task'larƒ± olu≈ütur
            vector_task = asyncio.create_task(
                self._get_vector_context_native(enhanced_question)
            )
            csv_task = asyncio.create_task(
                self._get_csv_context_safe(enhanced_question)
            )
            
            # Paralel y√ºr√ºtme
            try:
                context1, context2 = await asyncio.gather(
                    vector_task, 
                    csv_task, 
                    return_exceptions=True
                )
            except Exception as e:
                logger.error(f"Parallel processing error: {e}")
                context1 = "Vector search failed"
                context2 = "CSV analysis failed"
            
            parallel_time = time.time() - parallel_start
            
            # DETAYLI PERFORMANS LOGGING
            if os.getenv("DETAILED_TIMING", "false").lower() == "true":
                logger.info(f"‚è±Ô∏è Parallel processing: {parallel_time:.2f}s")
            
            # Exception'larƒ± handle et
            if isinstance(context1, Exception):
                logger.error(f"Vector context error: {context1}")
                context1 = "Vector search failed"
                
            if isinstance(context2, Exception):
                logger.error(f"CSV context error: {context2}")
                context2 = "CSV analysis failed"
            
            # Adƒ±m 4: Memory'den ge√ßmi≈ü al
            memory_start = time.time()
            conversation_history = self.memory.get_history(session_id)
            memory_time = time.time() - memory_start
            
            # Adƒ±m 5: Final yanƒ±t olu≈üturma - guidance parametreleri kaldƒ±rƒ±ldƒ±
            final_start = time.time()
            final_response = await self._generate_final_response_safe(
                question=enhanced_question,  # Enhanced question kullan
                context1=context1,
                context2=context2,
                history=conversation_history
            )
            final_time = time.time() - final_start
    
            # Memory'ye kaydet - orijinal mesajƒ± kaydet
            memory_save_start = time.time()
            self.memory.add_message(session_id, "user", message)  # Orijinal mesaj
            self.memory.add_message(session_id, "assistant", final_response)
            memory_save_time = time.time() - memory_save_start
    
            # PERFORMANS RAPORU
            total_time = time.time() - start_time
            
            # DETAYLI TIMING SADECE DETAILED_TIMING=true OLDUƒûUNDA
            if os.getenv("DETAILED_TIMING", "false").lower() == "true":
                logger.info(f"‚è±Ô∏è DETAILED BREAKDOWN:")
                logger.info(f"   üß† Smart Evaluator: {smart_time:.2f}s")
                logger.info(f"   üîÑ Parallel (Vector+CSV): {parallel_time:.2f}s")
                logger.info(f"   üíæ Memory fetch: {memory_time:.3f}s")
                logger.info(f"   üéØ Final response: {final_time:.2f}s")
                logger.info(f"   üíæ Memory save: {memory_save_time:.3f}s")
                logger.info(f"   üéâ TOTAL: {total_time:.2f}s")
                
                # PERFORMANS UYARI Sƒ∞STEMƒ∞
                if total_time > 10:
                    logger.warning(f"üêå SLOW REQUEST: {total_time:.2f}s")
                    if smart_time > 5:
                        logger.warning(f"   üß† Smart Evaluator slow: {smart_time:.2f}s")
                    if parallel_time > 5:
                        logger.warning(f"   üîÑ Parallel processing slow: {parallel_time:.2f}s")
                    if final_time > 3:
                        logger.warning(f"   üéØ Final response slow: {final_time:.2f}s")
            else:
                # SADECE TOPLAM S√úRE
                logger.info(f"Request completed in {total_time:.2f}s")
            
            return {
                "response": final_response,
                "metadata": {
                    "processing_time": round(total_time, 2),
                    **({
                        "smart_evaluator_time": round(smart_time, 2),
                        "parallel_time": round(parallel_time, 2),
                        "final_time": round(final_time, 2),
                        "enhanced_question": enhanced_question,
                        "original_question": message,
                        "status": status
                    } if AppSettings.DEBUG_MODE else {})
                }
            }
            
        except Exception as e:
            total_time = time.time() - start_time
            logger.error(f"Message processing error ({total_time:.2f}s): {e}")
            return {
                "response": MessageSettings.ERROR_GENERAL,
                "metadata": {"error": str(e), "processing_time": round(total_time, 2)}
            }                                            

    async def _get_vector_context_native(self, question: str) -> str:
        """Native AstraDB ile vector arama - Temizlenmi≈ü"""
        try:
            vector_start = time.time()
            
            if not self.astra_collection:
                logger.warning("Astra collection unavailable")
                return "Vector search unavailable"
            
            if AppSettings.LOG_VECTOR_DETAILS:
                logger.debug(f"Vector search starting: {question[:50]}...")
            
            # Embedding olu≈ütur
            try:
                query_embedding = self.get_embedding(question)
                if AppSettings.LOG_VECTOR_DETAILS:
                    logger.debug(f"Query embedding created: {len(query_embedding)} dimensions")
            except Exception as e:
                logger.error(f"Embedding creation error: {e}")
                return "Embedding creation failed"
            
            # Native vector search
            try:
                search_results = self.astra_collection.find(
                    {},
                    sort={"$vector": query_embedding},
                    limit=VectorConfig.SIMILARITY_TOP_K,
                    projection={
                        "$vectorize": 1,
                        "text": 1, 
                        "content": 1, 
                        "page_content": 1,
                        "body": 1,
                        "document": 1,
                        "metadata": 1,
                        "source": 1,
                        "file_path": 1,
                        "_id": 1
                    }
                )
                
                docs = list(search_results)
                
                if AppSettings.LOG_VECTOR_DETAILS:
                    logger.debug(f"Found {len(docs)} documents")
                
                if not docs:
                    logger.warning("No documents found")
                    return "No relevant documents found"
                
                # Dok√ºman i√ßeriklerini birle≈ütir
                context_parts = []
                total_chars = 0
                
                for i, doc in enumerate(docs):
                    try:
                        # ƒ∞√ßerik al
                        content = None
                        content_source = None
                        
                        if '$vectorize' in doc and doc['$vectorize']:
                            content = str(doc['$vectorize']).strip()
                            content_source = '$vectorize'
                        else:
                            # Fallback fields
                            possible_content_fields = ['text', 'content', 'page_content', 'body', 'document']
                            for field in possible_content_fields:
                                if field in doc and doc[field]:
                                    content = str(doc[field]).strip()
                                    content_source = field
                                    break
                        
                        if not content:
                            continue
                        
                        # ƒ∞√ßeriƒüi kƒ±salt
                        if len(content) > 800:
                            content = content[:800] + "..."
                        
                        context_parts.append(content)
                        total_chars += len(content)
                        
                        if AppSettings.LOG_VECTOR_DETAILS:
                            logger.debug(f"Document {i+1} processed: {len(content)} chars")
                        
                        if total_chars > 2000:
                            break
                            
                    except Exception as doc_error:
                        logger.error(f"Document {i+1} processing error: {doc_error}")
                        continue
                
                if not context_parts:
                    logger.error("No documents could be processed!")
                    return "Documents could not be processed"
                
                final_context = "\n\n".join(context_parts)
                vector_time = time.time() - vector_start
                
                if AppSettings.DETAILED_TIMING:
                    logger.debug(f"Vector search completed ({vector_time:.2f}s): {len(context_parts)} docs, {len(final_context)} chars")
                
                return final_context
                    
            except Exception as search_error:
                logger.error(f"Vector search error: {search_error}")
                return "Vector search failed"
            
        except Exception as e:
            vector_time = time.time() - vector_start
            logger.error(f"Vector context general error ({vector_time:.2f}s): {e}")
            return "Vector search general error"

    async def _get_csv_context_safe(self, question: str) -> str:
        """CSV analiz - Temizlenmi≈ü"""
        try:
            csv_start = time.time()
            
            if self.csv_data is None:
                if AppSettings.LOG_CSV_DETAILS:
                    logger.debug("CSV data unavailable")
                return "CSV data unavailable"

            question_lower = question.lower()
            
            if AppSettings.LOG_CSV_DETAILS:
                logger.debug(f"CSV analysis starting: {question_lower[:50]}...")
            
            # CSV anahtar kelimesi kontrol√º
            csv_keywords = [
                "istihdam", "maa≈ü", "gelir", "sekt√∂r", "firma", "√ßalƒ±≈üma", "i≈ü", 
                "giri≈üim", "ba≈ülama", "oran", "y√ºzde", "istatistik", "veri",
                "bilgisayar", "m√ºhendislik", "tƒ±p", "hukuk", "ekonomi", "matematik",
                "fizik", "kimya", "makine", "elektrik", "end√ºstri"
            ]
            
            csv_required = any(keyword in question_lower for keyword in csv_keywords)
            
            if AppSettings.LOG_CSV_DETAILS:
                logger.debug(f"CSV keywords check: {csv_required}")
            
            if not csv_required:
                return "CSV analysis not required"

            # B√∂l√ºm adƒ±nƒ± bul
            bolum_adi = None
            
            for bolum in self.csv_data['bolum_adi'].unique():
                if bolum.lower() in question_lower:
                    bolum_adi = bolum
                    break
            
            if not bolum_adi:
                for bolum in self.csv_data['bolum_adi'].unique():
                    bolum_words = bolum.lower().split()
                    if any(word in question_lower for word in bolum_words if len(word) > 3):
                        bolum_adi = bolum
                        break

            # Spesifik b√∂l√ºm analizi
            if bolum_adi:
                if AppSettings.LOG_CSV_DETAILS:
                    logger.debug(f"Specific department analysis: {bolum_adi}")
                
                filtered = self.csv_data[self.csv_data['bolum_adi'] == bolum_adi]
                
                if filtered.empty:
                    return f"No data found for {bolum_adi}"
                
                # Metrik s√ºtunlarƒ±nƒ± belirle
                metrik_cols = ["istihdam_orani", "girisimcilik_orani", "ortalama_calisma_suresi_ay"]
                
                if any(word in question_lower for word in ["istihdam", "√ßalƒ±≈üma", "i≈ü"]):
                    metrik_cols.extend([col for col in self.csv_data.columns if "istihdam" in col])
                    
                if any(word in question_lower for word in ["maa≈ü", "gelir", "salary"]):
                    metrik_cols.extend([col for col in self.csv_data.columns if col.startswith("maas_")])
                    
                if any(word in question_lower for word in ["sekt√∂r", "sector"]):
                    metrik_cols.extend([col for col in self.csv_data.columns if col.startswith("sektor_")])
                    
                if any(word in question_lower for word in ["firma", "≈üirket"]):
                    metrik_cols.extend([col for col in self.csv_data.columns if col.startswith("firma_")])
                
                metrik_cols = list(dict.fromkeys(metrik_cols))[:30]
                
                selected_cols = ['bolum_adi', 'gosterge_id'] + metrik_cols
                csv_snippet = filtered[selected_cols].to_string(index=False)
                
            else:
                # Genel analiz
                if AppSettings.LOG_CSV_DETAILS:
                    logger.debug("General CSV analysis")
                top_bolumler = self.csv_data.nlargest(5, 'istihdam_orani')
                sample_cols = ['bolum_adi', 'istihdam_orani', 'girisimcilik_orani', 'ortalama_calisma_suresi_ay']
                csv_snippet = top_bolumler[sample_cols].to_string(index=False)

            # CSV Agent'a sor
            if self.llm_csv_agent:
                try:
                    result = await self.llm_csv_agent.ainvoke(
                        self.csv_agent_prompt.format(
                            question=question,
                            csv_data=csv_snippet[:2000]
                        )
                    )
                    analysis = result.content.strip()
                    
                    if len(analysis) < 20:
                        analysis = f"CSV analysis completed. Basic data for {bolum_adi or 'relevant departments'}: {csv_snippet[:200]}..."
                        
                except Exception as agent_error:
                    logger.error(f"CSV Agent error: {agent_error}")
                    analysis = f"CSV data found: {csv_snippet[:300]}..."
            else:
                analysis = f"CSV data: {csv_snippet[:300]}..."

            csv_time = time.time() - csv_start
            
            if AppSettings.DETAILED_TIMING:
                logger.debug(f"CSV analysis completed ({csv_time:.2f}s)")
            
            return analysis

        except Exception as e:
            csv_time = time.time() - csv_start
            logger.error(f"CSV analysis error ({csv_time:.2f}s): {e}")
            return "CSV analysis error"
            
    async def _generate_final_response_safe(self, question: str, context1: str, context2: str, history: str = "") -> str:
        """Final yanƒ±t olu≈üturma - Guidance parametreleri kaldƒ±rƒ±ldƒ±"""
        try:
            if not self.llm_final:
                logger.error("Final LLM unavailable!")
                return "Response generation service temporarily unavailable."
            
            result = await self.llm_final.ainvoke(
                self.final_prompt.format(
                    question=question,
                    context1=context1,
                    context2=context2,
                    history=history
                )
            )
            
            final_response = result.content.strip()
            
            if AppSettings.LOG_LLM_RESPONSES:
                logger.debug(f"Final response generated: {len(final_response)} chars")
            
            return final_response
            
        except Exception as e:
            logger.error(f"Final response error: {e}")
            return "Error occurred while generating response."

    async def test_all_connections(self) -> Dict[str, str]:
        """Baƒülantƒ± testleri"""
        if AppSettings.DEBUG_MODE:
            logger.debug("Testing all connections...")
        results = {}
        
        # OpenAI Client test
        try:
            if self.openai_client:
                test_embedding = self.get_embedding("test")
                results["OpenAI Client"] = f"‚úÖ Connected ({len(test_embedding)} dimensions)"
            else:
                results["OpenAI Client"] = "‚ùå Client not initialized"
        except Exception as e:
            results["OpenAI Client"] = f"‚ùå Error: {str(e)[:50]}"
        
        # LLM testleri
        llm_tests = [
            ("Smart Evaluator-Corrector", self.llm_smart_evaluator_corrector),
            ("CSV Agent", self.llm_csv_agent),
            ("Final Response", self.llm_final)
        ]
        
        for name, llm in llm_tests:
            try:
                if llm:
                    await llm.ainvoke("Test")
                    results[name] = "‚úÖ Connected"
                else:
                    results[name] = "‚ùå Model not loaded"
            except Exception as e:
                results[name] = f"‚ùå Error: {str(e)[:50]}"
        
        # AstraDB test
        try:
            if self.astra_collection:
                test_results = list(self.astra_collection.find({}, limit=1))
                results["AstraDB Native"] = f"‚úÖ Connected ({len(test_results)} documents)"
            else:
                results["AstraDB Native"] = "‚ùå Collection not initialized"
        except Exception as e:
            results["AstraDB Native"] = f"‚ùå Error: {str(e)[:50]}"
        
        # CSV test
        try:
            if self.csv_data is not None:
                results["CSV"] = f"‚úÖ Loaded ({len(self.csv_data)} rows)"
            else:
                results["CSV"] = "‚ùå Not loaded"
        except Exception as e:
            results["CSV"] = f"‚ùå Error: {str(e)[:50]}"
        
        # Memory test
        try:
            self.memory.add_message("test_connection", "user", "test")
            history = self.memory.get_history("test_connection")
            if history:
                results["Memory"] = "‚úÖ Redis connected"
            else:
                results["Memory"] = "‚ö†Ô∏è Memory working but empty"
        except Exception as e:
            results["Memory"] = f"‚ùå Error: {str(e)[:50]}"
        
        return results

    # Debug fonksiyonlarƒ± - aynƒ± kaldƒ±
    async def debug_astra_documents(self) -> Dict[str, Any]:
        """AstraDB dok√ºman yapƒ±sƒ±nƒ± debug et"""
        try:
            if not self.astra_collection:
                return {"error": "AstraDB collection not initialized"}
            
            # ƒ∞lk 3 dok√ºmanƒ± al
            sample_docs = list(self.astra_collection.find({}, limit=3))
            
            debug_info = {
                "total_sample_docs": len(sample_docs),
                "sample_document_keys": [],
                "sample_content_preview": []
            }
            
            for i, doc in enumerate(sample_docs):
                debug_info["sample_document_keys"].append(list(doc.keys()))
                
                # ƒ∞√ßerik √∂nizlemesi
                content_preview = ""
                if '$vectorize' in doc:
                    content_preview = str(doc['$vectorize'])[:100]
                elif 'text' in doc:
                    content_preview = str(doc['text'])[:100]
                elif 'content' in doc:
                    content_preview = str(doc['content'])[:100]
                
                debug_info["sample_content_preview"].append(f"Doc {i+1}: {content_preview}")
            
            return debug_info
            
        except Exception as e:
            return {"error": f"Debug error: {str(e)}"}

    async def debug_csv_data(self) -> Dict[str, Any]:
        """CSV debug bilgileri"""
        try:
            if self.csv_data is None:
                return {"error": "CSV data not loaded"}
            
            debug_info = {
                "total_rows": len(self.csv_data),
                "total_columns": len(self.csv_data.columns),
                "column_names": list(self.csv_data.columns),
                "sample_departments": list(self.csv_data['bolum_adi'].head(5)),
                "data_types": dict(self.csv_data.dtypes.astype(str))
            }
            
            return debug_info
            
        except Exception as e:
            return {"error": f"CSV debug error: {str(e)}"}
