import os
import pandas as pd
import re
from typing import Dict, Any, List
import logging
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
import math
import json
import asyncio
import re
import time
from astrapy import DataAPIClient
from openai import OpenAI
from memory import ConversationMemory
from langchain_anthropic import ChatAnthropic

# Config imports
from config import (
    LLMConfigs, LLMProvider, VectorConfig, CSVConfig,
    PromptTemplates, CSV_KEYWORDS,
    DatabaseSettings, MessageSettings
)

logger = logging.getLogger(__name__)

class LLMFactory:
    @staticmethod
    def create_llm(config):
        """GeliÅŸmiÅŸ hata yÃ¶netimi ile LLM oluÅŸtur"""
        try:
            params = config.to_langchain_params()
            logger.info(f"ğŸ¤– LLM oluÅŸturuluyor: {config.provider.value} - {config.model}")
            
            if config.provider == LLMProvider.OPENAI:
                from langchain_openai import ChatOpenAI
                return ChatOpenAI(**params)
            elif config.provider == LLMProvider.GOOGLE:
                from langchain_google_genai import ChatGoogleGenerativeAI
                return ChatGoogleGenerativeAI(**params)
            elif config.provider == LLMProvider.ANTHROPIC:
                from langchain_anthropic import ChatAnthropic
                return ChatAnthropic(**params)
            else:
                raise ValueError(f"Desteklenmeyen provider: {config.provider}")
                
        except Exception as e:
            logger.error(f"âŒ LLM oluÅŸturma hatasÄ± ({config.provider.value}): {e}")
            raise

class TercihAsistaniProcessor:
    """
    GÃ¼ncellenmiÅŸ processor - Smart Evaluator-Corrector ile
    """
    
    def __init__(self):
        # YENÄ°: Smart Evaluator-Corrector
        self.llm_smart_evaluator_corrector = None
        
        # KALAN LLM'LER - eski evaluation ve correction kaldÄ±rÄ±ldÄ±
        self.llm_search_optimizer = None
        self.llm_csv_agent = None
        self.llm_final = None
        
        # Native Astrapy components
        self.openai_client = None
        self.astra_database = None
        self.astra_collection = None
        
        self.csv_data = None
        self.memory = ConversationMemory() 
        
        # YENÄ° PROMPT
        self.smart_evaluator_corrector_prompt = ChatPromptTemplate.from_template(
            PromptTemplates.SMART_EVALUATOR_CORRECTOR
        )
        
        # KALAN PROMPT'LAR - deÄŸiÅŸmedi
        self.search_optimizer_prompt = ChatPromptTemplate.from_template(PromptTemplates.SEARCH_OPTIMIZER)
        self.csv_agent_prompt = ChatPromptTemplate.from_template(PromptTemplates.CSV_AGENT)
        self.final_prompt = ChatPromptTemplate.from_template(PromptTemplates.FINAL_RESPONSE)

    def get_embedding(self, text: str) -> List[float]:
        """OpenAI embedding oluÅŸtur"""
        try:
            response = self.openai_client.embeddings.create(
                input=text,
                model="text-embedding-3-small"
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"âŒ Embedding oluÅŸturma hatasÄ±: {e}")
            raise

    def _get_recent_history(self, session_id: str, limit: int = 4) -> str:
        """Son N mesajÄ± al - Smart Evaluator iÃ§in"""
        try:
            if not self.memory:
                return ""
            
            # Memory'den son mesajlarÄ± al
            full_history = self.memory.get_history(session_id, limit=limit)
            
            if not full_history:
                return ""
            
            # Son 2-3 mesaj Ã§iftini al (user-assistant pairs)
            lines = full_history.strip().split('\n')
            recent_lines = lines[-4:] if len(lines) >= 4 else lines  # Son 4 satÄ±r (2 mesaj Ã§ifti)
            
            recent_history = '\n'.join(recent_lines)
            
            logger.info(f"ğŸ“œ Recent history alÄ±ndÄ±: {len(recent_history)} karakter")
            logger.info(f"   Ä°Ã§erik: '{recent_history[:100]}...'")
            
            return recent_history
            
        except Exception as e:
            logger.error(f"âŒ Recent history alma hatasÄ±: {e}")
            return ""

    async def initialize(self):
        """GÃ¼ncellenmiÅŸ baÅŸlatma - Smart Evaluator ile"""
        try:
            logger.info("ğŸš€ TercihAsistaniProcessor baÅŸlatÄ±lÄ±yor...")
            
            # API Key kontrolÃ¼
            self._check_api_keys()
            
            # OpenAI client'Ä± baÅŸlat
            self._initialize_openai_client()
            
            # YENÄ° LLM'leri sÄ±ralÄ± baÅŸlat
            await self._initialize_llms_new()
            
            # AstraDB baÄŸlantÄ±sÄ±nÄ± native API ile baÅŸlat
            await self._initialize_astradb_native()
            
            # CSV verilerini yÃ¼kle
            await self._initialize_csv()
                
            logger.info("âœ… TercihAsistaniProcessor baÅŸarÄ±yla baÅŸlatÄ±ldÄ±")
            
        except Exception as e:
            logger.error(f"âŒ Initialization hatasÄ±: {e}")
            raise

    def _check_api_keys(self):
        """API anahtarlarÄ±nÄ± kontrol et"""
        keys = {
            "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
            "ANTHROPIC_API_KEY": os.getenv("ANTHROPIC_API_KEY"),
            "GOOGLE_API_KEY": os.getenv("GOOGLE_API_KEY"),
            "ASTRA_DB_TOKEN": os.getenv("ASTRA_DB_TOKEN"),
            "ASTRA_DB_API_ENDPOINT": os.getenv("ASTRA_DB_API_ENDPOINT")
        }
        
        logger.info("ğŸ”‘ API Key durumu:")
        for key, value in keys.items():
            status = "âœ… Set" if value else "âŒ Missing"
            logger.info(f"   {key}: {status}")
            
        # Critical keys check
        if not keys["OPENAI_API_KEY"]:
            raise ValueError("OPENAI_API_KEY zorunlu!")

    def _initialize_openai_client(self):
        """OpenAI client'Ä± baÅŸlat"""
        try:
            self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            logger.info("âœ… OpenAI client baÅŸlatÄ±ldÄ±")
        except Exception as e:
            logger.error(f"âŒ OpenAI client hatasÄ±: {e}")
            raise

    async def _initialize_llms_new(self):
        """YENÄ° LLM baÅŸlatma - Smart Evaluator ile"""
        llm_configs = {
            "smart_evaluator_corrector": LLMConfigs.SMART_EVALUATOR_CORRECTOR,
            "search_optimizer": LLMConfigs.SEARCH_OPTIMIZER,
            "csv_agent": LLMConfigs.CSV_AGENT,
            "final": LLMConfigs.FINAL_RESPONSE
        }
        
        for name, config in llm_configs.items():
            try:
                llm = LLMFactory.create_llm(config)
                setattr(self, f"llm_{name}", llm)
                logger.info(f"âœ… {name} LLM baÅŸarÄ±lÄ±: {config.model}")
                
            except Exception as e:
                logger.error(f"âŒ {name} LLM hatasÄ±: {e}")
                
                # Critical LLM'ler iÃ§in fallback
                if name in ["smart_evaluator_corrector", "csv_agent", "final"]:
                    logger.warning(f"ğŸ”„ {name} iÃ§in OpenAI fallback...")
                    fallback_config = LLMConfigs.FINAL_RESPONSE  # OpenAI model
                    try:
                        llm = LLMFactory.create_llm(fallback_config)
                        setattr(self, f"llm_{name}", llm)
                        logger.info(f"âœ… {name} fallback baÅŸarÄ±lÄ±")
                    except Exception as fb_error:
                        logger.error(f"âŒ {name} fallback hatasÄ±: {fb_error}")
                        setattr(self, f"llm_{name}", None)

    async def _initialize_astradb_native(self):
        """AstraDB native API ile baÄŸlantÄ±"""
        try:
            logger.info("ğŸ”Œ AstraDB native API baÄŸlantÄ±sÄ± baÅŸlatÄ±lÄ±yor...")
            
            # Astra client oluÅŸtur
            astra_client = DataAPIClient(DatabaseSettings.ASTRA_DB_TOKEN)
            
            # Database baÄŸlantÄ±sÄ±
            self.astra_database = astra_client.get_database(
                DatabaseSettings.ASTRA_DB_API_ENDPOINT
            )
            
            # Collection al
            collection_name = DatabaseSettings.ASTRA_DB_COLLECTION
            self.astra_collection = self.astra_database.get_collection(collection_name)
            
            logger.info(f"âœ… AstraDB native baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ± - Collection: {collection_name}")
            
            # Test sorgusu
            test_results = list(self.astra_collection.find({}, limit=1))
            logger.info(f"âœ… Test sorgusu baÅŸarÄ±lÄ±: {len(test_results)} dokÃ¼man bulundu")
            
        except Exception as e:
            logger.error(f"âŒ AstraDB native baÄŸlantÄ± hatasÄ±: {e}")
            self.astra_database = None
            self.astra_collection = None

    async def _initialize_csv(self):
        """CSV verilerini gÃ¼venli yÃ¼kle"""
        try:
            csv_path = DatabaseSettings.CSV_FILE_PATH
            
            if not csv_path or not os.path.exists(csv_path):
                logger.warning(f"âš ï¸ CSV dosyasÄ± bulunamadÄ±: {csv_path}")
                self.csv_data = None
                return
            
            self.csv_data = pd.read_csv(csv_path)
            
            # Veri validasyonu
            if self.csv_data.empty:
                logger.warning("âš ï¸ CSV dosyasÄ± boÅŸ")
                self.csv_data = None
                return
            
            # Gerekli kolonlarÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
            required_cols = ['bolum_adi', 'gosterge_id']
            missing_cols = [col for col in required_cols if col not in self.csv_data.columns]
            
            if missing_cols:
                logger.error(f"âŒ CSV'de eksik kolonlar: {missing_cols}")
                self.csv_data = None
                return
            
            logger.info(f"âœ… CSV verisi yÃ¼klendi: {len(self.csv_data)} satÄ±r, {len(self.csv_data.columns)} kolon")
            
        except Exception as e:
            logger.error(f"âŒ CSV yÃ¼kleme hatasÄ±: {e}")
            self.csv_data = None

    async def _smart_evaluate_and_correct(self, message: str, session_id: str) -> Dict[str, str]:
        """YENÄ°: Smart Evaluator-Corrector fonksiyonu"""
        try:
            smart_start = time.time()
            
            if not self.llm_smart_evaluator_corrector:
                logger.warning("âš ï¸ Smart Evaluator-Corrector LLM mevcut deÄŸil, fallback")
                return {
                    "status": "UYGUN",
                    "enhanced_question": message
                }
            
            # Son birkaÃ§ mesajÄ± al
            recent_history = self._get_recent_history(session_id, limit=4)
            
            logger.info(f"ğŸ§  SMART EVALUATOR-CORRECTOR baÅŸlatÄ±lÄ±yor:")
            logger.info(f"   ğŸ“ Orijinal mesaj: '{message[:50]}...'")
            logger.info(f"   ğŸ“œ History: {len(recent_history)} karakter")
            
            # Smart Evaluator-Corrector'a gÃ¶nder
            result = await self.llm_smart_evaluator_corrector.ainvoke(
                self.smart_evaluator_corrector_prompt.format(
                    question=message,
                    history=recent_history
                )
            )
            
            response = result.content.strip()
            smart_time = time.time() - smart_start
            
            logger.info(f"ğŸ¤– Smart Evaluator-Corrector raw response ({smart_time:.2f}s):")
            logger.info(f"   ğŸ“„ Raw output: '{response[:150]}...'")
            
            # Response'u parse et
            try:
                # STATUS ve ENHANCED_QUESTION'u extract et
                status_match = re.search(r'STATUS:\s*(\w+)', response)
                question_match = re.search(r'ENHANCED_QUESTION:\s*(.+)', response, re.DOTALL)
                
                if status_match and question_match:
                    status = status_match.group(1).strip()
                    enhanced_question = question_match.group(1).strip()
                    
                    logger.info(f"âœ… PARSE BAÅARILI:")
                    logger.info(f"   ğŸ“Š Status: {status}")
                    logger.info(f"   ğŸ“ Enhanced Q: '{enhanced_question[:80]}...'")
                    
                    return {
                        "status": status,
                        "enhanced_question": enhanced_question
                    }
                else:
                    logger.warning("âš ï¸ Parse baÅŸarÄ±sÄ±z - format hatasÄ±")
                    logger.warning(f"   Status match: {bool(status_match)}")
                    logger.warning(f"   Question match: {bool(question_match)}")
                    
                    # Fallback parsing
                    if "UYGUN" in response.upper():
                        return {"status": "UYGUN", "enhanced_question": message}
                    elif "SELAMLAMA" in response.upper():
                        return {"status": "SELAMLAMA", "enhanced_question": message}
                    else:
                        return {"status": "KAPSAM_DIÅI", "enhanced_question": message}
                        
            except Exception as parse_error:
                logger.error(f"âŒ Parse hatasÄ±: {parse_error}")
                return {"status": "UYGUN", "enhanced_question": message}
            
        except Exception as e:
            smart_time = time.time() - smart_start
            logger.error(f"âŒ Smart Evaluator-Corrector hatasÄ± ({smart_time:.2f}s): {e}")
            return {"status": "UYGUN", "enhanced_question": message}

    async def process_message(self, message: str, session_id: str = "default") -> Dict[str, Any]:
        """YENÄ° akÄ±ÅŸ ile mesaj iÅŸleme"""
        start_time = time.time()
        
        try:
            logger.info(f"ğŸ“¨ Mesaj iÅŸleniyor - Session: {session_id}")
            logger.info(f"ğŸ“ Gelen mesaj: '{message[:100]}...' ({len(message)} karakter)")
            
            # AdÄ±m 1: YENÄ° Smart Evaluator-Corrector
            smart_start = time.time()
            smart_result = await self._smart_evaluate_and_correct(message, session_id)
            smart_time = time.time() - smart_start
            
            status = smart_result["status"]
            enhanced_question = smart_result["enhanced_question"]
            
            logger.info(f"â±ï¸ Smart Evaluator-Corrector sÃ¼resi: {smart_time:.2f}s")
            logger.info(f"ğŸ“Š Status: {status}")
            logger.info(f"ğŸ“ Enhanced Question: '{enhanced_question[:100]}...'")
            
            # AdÄ±m 2: KoÅŸullu yÃ¶nlendirme
            if status == "KAPSAM_DIÅI":
                total_time = time.time() - start_time
                logger.info(f"ğŸš« Kapsam dÄ±ÅŸÄ± soru - Toplam sÃ¼re: {total_time:.2f}s")
                return {
                    "response": MessageSettings.ERROR_EXPERTISE_OUT,
                    "sources": []
                }
            
            if status == "SELAMLAMA":
                total_time = time.time() - start_time
                logger.info(f"ğŸ‘‹ Selamlama algÄ±landÄ± - Toplam sÃ¼re: {total_time:.2f}s")
                return {
                    "response": "Merhaba! Ben bir Ã¼niversite tercih asistanÄ±yÄ±m. Size YKS tercihleri, bÃ¶lÃ¼m seÃ§imi, kariyer planlamasÄ± konularÄ±nda yardÄ±mcÄ± olabilirim. Hangi konuda bilgi almak istiyorsunuz?",
                    "sources": []
                }
            
            # AdÄ±m 3: PARALEL Ä°ÅLEMLER - Enhanced question ile
            parallel_start = time.time()
            logger.info("ğŸ”„ Paralel iÅŸlemler baÅŸlatÄ±lÄ±yor...")
            
            # Task'larÄ± oluÅŸtur
            vector_task = asyncio.create_task(
                self._get_vector_context_native(enhanced_question)
            )
            csv_task = asyncio.create_task(
                self._get_csv_context_safe(enhanced_question)
            )
            
            # Paralel yÃ¼rÃ¼tme
            try:
                context1, context2 = await asyncio.gather(
                    vector_task, 
                    csv_task, 
                    return_exceptions=True
                )
            except Exception as e:
                logger.error(f"âŒ Paralel iÅŸleme genel hatasÄ±: {e}")
                context1 = "Vector arama baÅŸarÄ±sÄ±z"
                context2 = "CSV analizi baÅŸarÄ±sÄ±z"
            
            parallel_time = time.time() - parallel_start
            logger.info(f"â±ï¸ Paralel iÅŸlemler toplam sÃ¼resi: {parallel_time:.2f}s")
            
            # Exception'larÄ± handle et
            if isinstance(context1, Exception):
                logger.error(f"âŒ Vector context hatasÄ±: {context1}")
                context1 = "Vector arama baÅŸarÄ±sÄ±z"
                
            if isinstance(context2, Exception):
                logger.error(f"âŒ CSV context hatasÄ±: {context2}")
                context2 = "CSV analizi baÅŸarÄ±sÄ±z"
            
            # Context detaylarÄ±nÄ± logla
            logger.info(f"ğŸ“„ CONTEXT1 (Vector) - {len(context1)} karakter")
            logger.info(f"ğŸ“Š CONTEXT2 (CSV) - {len(context2)} karakter")
            
            # AdÄ±m 4: Memory'den geÃ§miÅŸ al
            memory_start = time.time()
            conversation_history = self.memory.get_history(session_id)
            memory_time = time.time() - memory_start
            logger.info(f"ğŸ§  Memory geÃ§miÅŸi alÄ±ndÄ± ({memory_time:.3f}s): {len(conversation_history)} karakter")
            
            # AdÄ±m 5: Final yanÄ±t oluÅŸturma - Enhanced question ile
            final_start = time.time()
            final_response = await self._generate_final_response_safe(
                question=enhanced_question,  # Enhanced question kullan
                context1=context1,
                context2=context2,
                history=conversation_history
            )
            final_time = time.time() - final_start
            logger.info(f"â±ï¸ Final response sÃ¼resi: {final_time:.2f}s")
            logger.info(f"âœ… Final yanÄ±t: {len(final_response)} karakter")

            # Memory'ye kaydet - orijinal mesajÄ± kaydet
            memory_save_start = time.time()
            self.memory.add_message(session_id, "user", message)  # Orijinal mesaj
            self.memory.add_message(session_id, "assistant", final_response)
            memory_save_time = time.time() - memory_save_start
            logger.info(f"ğŸ’¾ Memory kayÄ±t tamamlandÄ± ({memory_save_time:.3f}s)")

            # PERFORMANS RAPORU
            total_time = time.time() - start_time
            logger.info(f"ğŸ“ˆ PERFORMANS RAPORU:")
            logger.info(f"   ğŸ§  Smart Evaluator-Corrector: {smart_time:.2f}s")
            logger.info(f"   ğŸ”„ Paralel Ä°ÅŸlemler: {parallel_time:.2f}s")
            logger.info(f"   ğŸ§  Memory: {memory_time:.3f}s")
            logger.info(f"   ğŸ¯ Final Response: {final_time:.2f}s")
            logger.info(f"   ğŸ’¾ Memory Save: {memory_save_time:.3f}s")
            logger.info(f"   ğŸ‰ TOPLAM: {total_time:.2f}s")
            
            return {
                "response": final_response,
                "sources": self._extract_sources(context1, context2),
                "metadata": {
                    "processing_time": round(total_time, 2),
                    "smart_evaluator_time": round(smart_time, 2),
                    "parallel_time": round(parallel_time, 2),
                    "enhanced_question": enhanced_question,
                    "original_question": message,
                    "status": status
                }
            }
            
        except Exception as e:
            total_time = time.time() - start_time
            logger.error(f"âŒ Mesaj iÅŸleme genel hatasÄ± ({total_time:.2f}s): {e}")
            return {
                "response": MessageSettings.ERROR_GENERAL,
                "sources": [],
                "metadata": {"error": str(e), "processing_time": round(total_time, 2)}
            }

    async def _get_vector_context_native(self, question: str) -> str:
        """Native AstraDB ile vector arama"""
        try:
            vector_start = time.time()
            
            if not self.astra_collection:
                logger.warning("âŒ Astra collection mevcut deÄŸil")
                return "Vector arama mevcut deÄŸil"
            
            logger.info(f"ğŸ” Native vector arama baÅŸlatÄ±lÄ±yor: {question[:50]}...")
            
            # Search query optimize et
            search_text = question
            if self.llm_search_optimizer:
                try:
                    optimized_query = await self.llm_search_optimizer.ainvoke(
                        self.search_optimizer_prompt.format(question=question)
                    )
                    search_text = optimized_query.content.strip()
                    logger.info(f"âœ¨ Optimize edilmiÅŸ sorgu: {search_text[:80]}...")
                except Exception as e:
                    logger.warning(f"âš ï¸ Sorgu optimizasyonu baÅŸarÄ±sÄ±z: {e}")
            
            # Embedding oluÅŸtur
            try:
                query_embedding = self.get_embedding(search_text)
                logger.info(f"âœ… Query embedding oluÅŸturuldu: {len(query_embedding)} boyut")
            except Exception as e:
                logger.error(f"âŒ Embedding oluÅŸturma hatasÄ±: {e}")
                return "Embedding oluÅŸturulamadÄ±"
            
            # Native vector search
            try:
                search_results = self.astra_collection.find(
                    {},
                    sort={"$vector": query_embedding},
                    limit=VectorConfig.SIMILARITY_TOP_K,
                    projection={
                        "$vectorize": 1,
                        "text": 1, 
                        "content": 1, 
                        "page_content": 1,
                        "body": 1,
                        "document": 1,
                        "metadata": 1,
                        "source": 1,
                        "file_path": 1,
                        "_id": 1
                    }
                )
                
                docs = list(search_results)
                logger.info(f"ğŸ“„ Bulunan dokÃ¼man sayÄ±sÄ±: {len(docs)}")
                
                if not docs:
                    logger.warning("âŒ HiÃ§ dokÃ¼man bulunamadÄ±")
                    return "Ä°lgili dokÃ¼man bulunamadÄ±"
                
                # DokÃ¼man iÃ§eriklerini birleÅŸtir
                context_parts = []
                total_chars = 0
                
                for i, doc in enumerate(docs):
                    try:
                        # Ä°Ã§erik al
                        content = None
                        content_source = None
                        
                        if '$vectorize' in doc and doc['$vectorize']:
                            content = str(doc['$vectorize']).strip()
                            content_source = '$vectorize'
                        else:
                            # Fallback fields
                            possible_content_fields = ['text', 'content', 'page_content', 'body', 'document']
                            for field in possible_content_fields:
                                if field in doc and doc[field]:
                                    content = str(doc[field]).strip()
                                    content_source = field
                                    break
                        
                        if not content:
                            continue
                        
                        # Kaynak bilgisi
                        source = "Bilinmeyen kaynak"
                        if 'metadata' in doc and isinstance(doc['metadata'], dict):
                            metadata = doc['metadata']
                            source = metadata.get('source', metadata.get('file_path', metadata.get('filename', source)))
                        elif 'source' in doc:
                            source = doc['source']
                        elif 'file_path' in doc:
                            source = doc['file_path']
                        
                        # Ä°Ã§eriÄŸi kÄ±salt
                        if len(content) > 800:
                            content = content[:800] + "..."
                        
                        # Kaynak formatÄ±nÄ± dÃ¼zelt
                        if isinstance(source, str):
                            source_name = source.split('/')[-1] if '/' in source else source
                            if any(char in source_name for char in ['Ã„Â°', 'ZÃƒ', 'Ãƒ', 'Ã‚']):
                                source_name = "Ä°ZÃœ YKS Tercih Rehberi.pdf"
                            if not source_name or source_name == "Bilinmeyen kaynak":
                                source_name = "Tercih Rehberi"
                        else:
                            source_name = "Rehber DokÃ¼manÄ±"
                        
                        context_parts.append(f"**Kaynak**: {source_name}\n**Ä°Ã§erik**: {content}")
                        total_chars += len(content)
                        
                        logger.info(f"âœ… DokÃ¼man {i+1} iÅŸlendi: {source_name} - {len(content)} karakter")
                        
                        if total_chars > 2000:
                            break
                            
                    except Exception as doc_error:
                        logger.error(f"âŒ DokÃ¼man {i+1} iÅŸleme hatasÄ±: {doc_error}")
                        continue
                
                if not context_parts:
                    logger.error("âŒ HiÃ§bir dokÃ¼man iÅŸlenemedi!")
                    return "DokÃ¼manlar iÅŸlenemedi"
                
                final_context = "\n\n".join(context_parts)
                vector_time = time.time() - vector_start
                
                logger.info(f"âœ… NATIVE VECTOR ARAMA TAMAMLANDI ({vector_time:.2f}s):")
                logger.info(f"   ğŸ“„ Ä°ÅŸlenen dokÃ¼man: {len(context_parts)} adet")
                logger.info(f"   ğŸ“ Toplam context: {len(final_context)} karakter")
                
                return final_context
                    
            except Exception as search_error:
                logger.error(f"âŒ Vector arama hatasÄ±: {search_error}")
                return "Vector arama baÅŸarÄ±sÄ±z"
            
        except Exception as e:
            vector_time = time.time() - vector_start
            logger.error(f"âŒ Vector context genel hatasÄ± ({vector_time:.2f}s): {e}")
            return "Vector arama genel hatasÄ±"

    async def _get_csv_context_safe(self, question: str) -> str:
        """CSV analiz - Enhanced question ile"""
        try:
            csv_start = time.time()
            
            if self.csv_data is None:
                logger.info("âŒ CSV verileri mevcut deÄŸil")
                return "CSV verileri mevcut deÄŸil"
    
            question_lower = question.lower()
            logger.info(f"ğŸ” CSV analizi: '{question_lower[:50]}...'")
            
            # CSV anahtar kelimesi kontrolÃ¼
            csv_keywords = [
                "istihdam", "maaÅŸ", "gelir", "sektÃ¶r", "firma", "Ã§alÄ±ÅŸma", "iÅŸ", 
                "giriÅŸim", "baÅŸlama", "oran", "yÃ¼zde", "istatistik", "veri",
                "bilgisayar", "mÃ¼hendislik", "tÄ±p", "hukuk", "ekonomi", "matematik",
                "fizik", "kimya", "makine", "elektrik", "endÃ¼stri"
            ]
            
            csv_required = any(keyword in question_lower for keyword in csv_keywords)
            logger.info(f"ğŸ” CSV Keywords check: {csv_required}")
            
            if not csv_required:
                logger.info("âš¡ CSV analizi atlandÄ±")
                return "CSV analizi gerekli deÄŸil"
    
            # BÃ¶lÃ¼m adÄ±nÄ± bul
            bolum_adi = None
            
            for bolum in self.csv_data['bolum_adi'].unique():
                if bolum.lower() in question_lower:
                    bolum_adi = bolum
                    break
            
            if not bolum_adi:
                for bolum in self.csv_data['bolum_adi'].unique():
                    bolum_words = bolum.lower().split()
                    if any(word in question_lower for word in bolum_words if len(word) > 3):
                        bolum_adi = bolum
                        break
    
            # Spesifik bÃ¶lÃ¼m analizi
            if bolum_adi:
                logger.info(f"ğŸ“‹ Spesifik bÃ¶lÃ¼m analizi: {bolum_adi}")
                
                filtered = self.csv_data[self.csv_data['bolum_adi'] == bolum_adi]
                
                if filtered.empty:
                    return f"{bolum_adi} iÃ§in veri bulunamadÄ±"
                
                # Metrik sÃ¼tunlarÄ±nÄ± belirle
                metrik_cols = ["istihdam_orani", "girisimcilik_orani", "ortalama_calisma_suresi_ay"]
                
                if any(word in question_lower for word in ["istihdam", "Ã§alÄ±ÅŸma", "iÅŸ"]):
                    metrik_cols.extend([col for col in self.csv_data.columns if "istihdam" in col])
                    
                if any(word in question_lower for word in ["maaÅŸ", "gelir", "salary"]):
                    metrik_cols.extend([col for col in self.csv_data.columns if col.startswith("maas_")])
                    
                if any(word in question_lower for word in ["sektÃ¶r", "sector"]):
                    metrik_cols.extend([col for col in self.csv_data.columns if col.startswith("sektor_")])
                    
                if any(word in question_lower for word in ["firma", "ÅŸirket"]):
                    metrik_cols.extend([col for col in self.csv_data.columns if col.startswith("firma_")])
                
                metrik_cols = list(dict.fromkeys(metrik_cols))[:30]
                
                selected_cols = ['bolum_adi', 'gosterge_id'] + metrik_cols
                csv_snippet = filtered[selected_cols].to_string(index=False)
                
            else:
                # Genel analiz
                logger.info("ğŸ“ˆ Genel CSV analizi")
                top_bolumler = self.csv_data.nlargest(5, 'istihdam_orani')
                sample_cols = ['bolum_adi', 'istihdam_orani', 'girisimcilik_orani', 'ortalama_calisma_suresi_ay']
                csv_snippet = top_bolumler[sample_cols].to_string(index=False)
    
            # CSV Agent'a sor
            if self.llm_csv_agent:
                try:
                    result = await self.llm_csv_agent.ainvoke(
                        self.csv_agent_prompt.format(
                            question=question,
                            csv_data=csv_snippet[:2000]
                        )
                    )
                    analysis = result.content.strip()
                    
                    if len(analysis) < 20:
                        analysis = f"CSV analizi tamamlandÄ±. {bolum_adi or 'Ä°lgili bÃ¶lÃ¼mler'} iÃ§in temel veriler: {csv_snippet[:200]}..."
                        
                except Exception as agent_error:
                    logger.error(f"âŒ CSV Agent hatasÄ±: {agent_error}")
                    analysis = f"CSV verisi bulundu: {csv_snippet[:300]}..."
            else:
                analysis = f"CSV verisi: {csv_snippet[:300]}..."
    
            csv_time = time.time() - csv_start
            logger.info(f"â±ï¸ CSV analizi sÃ¼resi: {csv_time:.2f}s")
            
            return analysis
    
        except Exception as e:
            csv_time = time.time() - csv_start
            logger.error(f"âŒ CSV analiz hatasÄ± ({csv_time:.2f}s): {e}")
            return "CSV analizi hatasÄ±"
            
    async def _generate_final_response_safe(self, question: str, context1: str, context2: str, history: str = "") -> str:
        """Final yanÄ±t oluÅŸturma"""
        try:
            if not self.llm_final:
                logger.error("âŒ Final LLM mevcut deÄŸil!")
                return "YanÄ±t oluÅŸturma servisi geÃ§ici olarak kullanÄ±lamÄ±yor."
            
            result = await self.llm_final.ainvoke(
                self.final_prompt.format(
                    question=question,
                    context1=context1,
                    context2=context2,
                    history=history
                )
            )
            
            final_response = result.content.strip()
            logger.info(f"âœ… Final response oluÅŸturuldu: {len(final_response)} karakter")
            
            return final_response
            
        except Exception as e:
            logger.error(f"âŒ Final yanÄ±t hatasÄ±: {e}")
            return "YanÄ±t oluÅŸturulurken hata oluÅŸtu."

    def _extract_sources(self, context1: str, context2: str) -> List[str]:
        """Kaynak Ã§Ä±karma"""
        sources = []
        
        # Vector context kontrolÃ¼
        if context1 and len(context1.strip()) > 50:
            error_keywords = ["bulunamadÄ±", "baÅŸarÄ±sÄ±z", "mevcut deÄŸil", "hata"]
            has_error = any(keyword in context1.lower() for keyword in error_keywords)
            
            if not has_error:
                if "Ä°ZÃœ" in context1 or "tercih rehberi" in context1.lower():
                    sources.append(MessageSettings.SOURCES["IZU_GUIDE"])
                elif "yÃ¶k" in context1.lower():
                    sources.append(MessageSettings.SOURCES["YOK_REPORT"])
                else:
                    sources.append(MessageSettings.SOURCES["IZU_GUIDE"])
        
        # CSV context kontrolÃ¼
        if context2 and len(context2.strip()) > 50:
            csv_error_keywords = ["mevcut deÄŸil", "hata", "baÅŸarÄ±sÄ±z", "gerekli deÄŸil"]
            has_csv_error = any(keyword in context2.lower() for keyword in csv_error_keywords)
            
            if not has_csv_error:
                csv_success_indicators = ["analiz", "oran", "veri", "bÃ¶lÃ¼m", "istihdam", "maaÅŸ", "%"]
                has_csv_content = any(indicator in context2.lower() for indicator in csv_success_indicators)
                
                if has_csv_content:
                    sources.append(MessageSettings.SOURCES["UNIVERI_DB"])
        
        if not sources:
            sources.append(MessageSettings.SOURCES["GENERAL"])
        
        return list(dict.fromkeys(sources))

    async def test_all_connections(self) -> Dict[str, str]:
        """BaÄŸlantÄ± testleri"""
        logger.info("ğŸ§ª TÃœM BAÄLANTILAR TEST EDÄ°LÄ°YOR...")
        results = {}
        
        # OpenAI Client test
        try:
            if self.openai_client:
                test_embedding = self.get_embedding("test")
                results["OpenAI Client"] = f"âœ… BaÄŸlÄ± ({len(test_embedding)} boyut)"
            else:
                results["OpenAI Client"] = "âŒ Client baÅŸlatÄ±lmadÄ±"
        except Exception as e:
            results["OpenAI Client"] = f"âŒ Hata: {str(e)[:50]}"
        
        # LLM testleri
        llm_tests = [
            ("Smart Evaluator-Corrector", self.llm_smart_evaluator_corrector),
            ("Search Optimizer", self.llm_search_optimizer),
            ("CSV Agent", self.llm_csv_agent),
            ("Final Response", self.llm_final)
        ]
        
        for name, llm in llm_tests:
            try:
                if llm:
                    await llm.ainvoke("Test")
                    results[name] = "âœ… BaÄŸlÄ±"
                else:
                    results[name] = "âŒ Model yÃ¼klenmedi"
            except Exception as e:
                results[name] = f"âŒ Hata: {str(e)[:50]}"
        
        # AstraDB test
        try:
            if self.astra_collection:
                test_results = list(self.astra_collection.find({}, limit=1))
                results["AstraDB Native"] = f"âœ… BaÄŸlÄ± ({len(test_results)} dokÃ¼man)"
            else:
                results["AstraDB Native"] = "âŒ Collection baÅŸlatÄ±lmadÄ±"
        except Exception as e:
            results["AstraDB Native"] = f"âŒ Hata: {str(e)[:50]}"
        
        # CSV test
        try:
            if self.csv_data is not None:
                results["CSV"] = f"âœ… YÃ¼klÃ¼ ({len(self.csv_data)} satÄ±r)"
            else:
                results["CSV"] = "âŒ YÃ¼klenmedi"
        except Exception as e:
            results["CSV"] = f"âŒ Hata: {str(e)[:50]}"
        
        # Memory test
        try:
            self.memory.add_message("test_connection", "user", "test")
            history = self.memory.get_history("test_connection")
            if history:
                results["Memory"] = "âœ… Redis baÄŸlÄ±"
            else:
                results["Memory"] = "âš ï¸ Memory Ã§alÄ±ÅŸÄ±yor ama boÅŸ"
        except Exception as e:
            results["Memory"] = f"âŒ Hata: {str(e)[:50]}"
        
        return results
